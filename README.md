# atlas-ia-assist

# ğŸ§  Atlas IA Assist

**Atlas IA Assist** Ã© um assistente pessoal conversacional construÃ­do com modelos LLaMA rodando localmente via Ollama. O foco do projeto Ã© **conversa, escuta, reflexÃ£o e acompanhamento do usuÃ¡rio**, sem automaÃ§Ãµes de trabalho ou foco em dados corporativos.

Atlas nÃ£o Ã© um bot de tarefas. Ele Ã© um **companheiro de diÃ¡logo**, projetado para ajudar o usuÃ¡rio a pensar, organizar ideias e lidar com decisÃµes do dia a dia.

---

## âœ¨ Filosofia do Projeto

Atlas foi pensado com alguns princÃ­pios claros:

- ğŸ¤ **PresenÃ§a antes de produtividade**
- ğŸ§  **MemÃ³ria com cuidado e contexto**
- ğŸ—£ï¸ **Linguagem humana, calma e respeitosa**
- âŒ Nada de respostas robÃ³ticas ou tÃ©cnicas sem necessidade
- ğŸ”’ ExecuÃ§Ã£o local, respeitando privacidade

Atlas nÃ£o substitui decisÃµes. Ele **caminha junto** enquanto vocÃª as constrÃ³i.

---

## ğŸš€ Funcionalidades Atuais

- âœ… Chat conversacional via terminal
- âœ… IntegraÃ§Ã£o com **Ollama** (LLaMA local)
- âœ… **MemÃ³ria persistente** em arquivo JSON
- âœ… Contexto inicial com histÃ³rico recente
- âœ… Prompt de sistema com identidade do assistente

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.10+**
- **Ollama** (execuÃ§Ã£o local de LLMs)
- **Modelo LLaMA** (ex: `llama3`, `llama3.1` â€“ conforme memÃ³ria disponÃ­vel)
- **Requests** (comunicaÃ§Ã£o HTTP)
- **JSON** (persistÃªncia de memÃ³ria)

---

## ğŸ“ Estrutura do Projeto

```text
atlas_ia_assist/
â”‚
â”œâ”€â”€ llamaIA.py           # Script principal do assistente
â”œâ”€â”€ memoria.json         # MemÃ³ria persistente do usuÃ¡rio
â”œâ”€â”€ README.md            # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt     # DependÃªncias (opcional)
```

---

## âš™ï¸ PrÃ©-requisitos

1. **Python instalado** (recomendado 3.10+)
2. **Ollama instalado e rodando**
3. Modelo LLaMA baixado

Exemplo:

```bash
ollama pull llama3
ollama run llama3
```

âš ï¸ Importante: o Ollama **precisa estar aberto** para o Atlas funcionar.

---

## â–¶ï¸ Como Executar

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/seu-usuario/atlas_ia_assist.git
cd atlas_ia_assist
```

2. (Opcional) Crie um ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. Instale as dependÃªncias

```bash
pip install requests
```

4. Execute o assistente

```bash
python llamaIA.py
```

---

## ğŸ§  Como Funciona a MemÃ³ria

A memÃ³ria do Atlas:

- Ã‰ armazenada em `memoria.json`
- Guarda interaÃ§Ãµes recentes
- Ã‰ reinjetada no contexto inicial do modelo
- Tem limite para evitar crescimento infinito

âš ï¸ Atualmente a memÃ³ria Ã© **simples e literal**. EvoluÃ§Ãµes futuras tornarÃ£o isso mais inteligente.

---

## ğŸ—ºï¸ Roadmap (PrÃ³ximos Passos)

### Curto Prazo

- [ ] SeparaÃ§Ã£o de memÃ³ria (fatos, preferÃªncias, emoÃ§Ãµes)
- [ ] Resumo automÃ¡tico da memÃ³ria
- [ ] Arquivo de persona (`atlas_persona.txt`)

### MÃ©dio Prazo

- [ ] Entrada por voz (speech-to-text)
- [ ] Resposta falada (text-to-speech)
- [ ] DetecÃ§Ã£o de temas recorrentes

### Longo Prazo

- [ ] MemÃ³ria semÃ¢ntica (embeddings)
- [ ] Interface grÃ¡fica simples
- [ ] Modo diÃ¡rio / reflexivo

---

## ğŸ§© Exemplo de Uso

```text
VocÃª: estou meio confuso com algumas decisÃµes

Atlas: Quer me contar o que estÃ¡ pesando mais agora? Ã€s vezes organizar em palavras jÃ¡ ajuda a clarear.
```

---

## ğŸ”’ Privacidade

- Atlas roda **100% local**
- Nenhuma conversa Ã© enviada para serviÃ§os externos
- Toda a memÃ³ria fica no seu computador

---

## ğŸ¤ ContribuiÃ§Ãµes

Este projeto nasceu como um assistente pessoal, mas contribuiÃ§Ãµes sÃ£o bem-vindas:

- Ideias
- Melhorias na memÃ³ria
- Ajustes de prompt
- EvoluÃ§Ãµes de UX

---

## ğŸ“œ LicenÃ§a

Defina a licenÃ§a conforme sua preferÃªncia (MIT, Apache, GPL, etc).

---

## ğŸŒ Nome do Projeto

**Atlas IA Assist**

> Um assistente que ajuda a sustentar pensamentos, nÃ£o a substituÃ­-los.
